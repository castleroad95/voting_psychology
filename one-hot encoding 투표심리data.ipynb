{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>363</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1370</td>\n",
       "      <td>5.0</td>\n",
       "      <td>997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>647</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1313</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>707</td>\n",
       "      <td>5.0</td>\n",
       "      <td>556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA  ...  wr_04  wr_05  \\\n",
       "0      0  3.0   363  4.0  1370  5.0   997  1.0  1024  2.0  ...      0      1   \n",
       "1      1  5.0   647  5.0  1313  3.0  3387  5.0  2969  1.0  ...      1      1   \n",
       "2      2  4.0  1623  1.0  1480  1.0  1021  4.0  3374  5.0  ...      1      1   \n",
       "3      3  3.0   504  3.0  2311  4.0   992  3.0  3245  1.0  ...      0      0   \n",
       "4      4  1.0   927  1.0   707  5.0   556  2.0  1062  1.0  ...      1      1   \n",
       "\n",
       "   wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "0      0      1      1      0      1      0      1      1  \n",
       "1      0      1      1      0      1      0      1      1  \n",
       "2      0      1      1      1      1      0      1      1  \n",
       "3      0      0      1      0      1      0      1      1  \n",
       "4      1      1      1      0      1      1      1      1  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_csv = pd.read_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/input/train.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QaE\n",
      "QbE\n",
      "QcE\n",
      "QdE\n",
      "QeE\n",
      "QfE\n",
      "QgE\n",
      "QhE\n",
      "QiE\n",
      "QjE\n",
      "QkE\n",
      "QlE\n",
      "QmE\n",
      "QnE\n",
      "QoE\n",
      "QpE\n",
      "QqE\n",
      "QrE\n",
      "QsE\n",
      "QtE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QaA</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QeA</th>\n",
       "      <th>QfA</th>\n",
       "      <th>QgA</th>\n",
       "      <th>QhA</th>\n",
       "      <th>QiA</th>\n",
       "      <th>QjA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45527</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45528</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45529</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45530</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45531</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45532 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QaA  QbA  QcA  QdA  QeA  QfA  QgA  QhA  QiA  QjA  ...  wr_04  wr_05  \\\n",
       "0      3.0  4.0  5.0  1.0  2.0  5.0  2.0  4.0  5.0  4.0  ...      0      1   \n",
       "1      5.0  5.0  3.0  5.0  1.0  3.0  1.0  1.0  5.0  3.0  ...      1      1   \n",
       "2      4.0  1.0  1.0  4.0  5.0  1.0  4.0  1.0  3.0  2.0  ...      1      1   \n",
       "3      3.0  3.0  4.0  3.0  1.0  2.0  4.0  3.0  5.0  4.0  ...      0      0   \n",
       "4      1.0  1.0  5.0  2.0  1.0  2.0  1.0  1.0  5.0  5.0  ...      1      1   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "45527  2.0  5.0  4.0  1.0  1.0  1.0  1.0  1.0  1.0  4.0  ...      1      1   \n",
       "45528  2.0  3.0  4.0  1.0  3.0  2.0  2.0  1.0  2.0  5.0  ...      1      1   \n",
       "45529  4.0  1.0  1.0  4.0  5.0  4.0  5.0  1.0  5.0  1.0  ...      1      1   \n",
       "45530  1.0  3.0  4.0  2.0  1.0  1.0  1.0  1.0  5.0  1.0  ...      1      1   \n",
       "45531  3.0  5.0  5.0  3.0  1.0  4.0  3.0  3.0  4.0  4.0  ...      1      1   \n",
       "\n",
       "       wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "0          0      1      1      0      1      0      1      1  \n",
       "1          0      1      1      0      1      0      1      1  \n",
       "2          0      1      1      1      1      0      1      1  \n",
       "3          0      0      1      0      1      0      1      1  \n",
       "4          1      1      1      0      1      1      1      1  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "45527      0      1      1      1      1      0      1      1  \n",
       "45528      0      1      1      1      1      0      1      1  \n",
       "45529      0      1      1      0      1      0      1      1  \n",
       "45530      0      1      1      1      1      0      1      1  \n",
       "45531      0      1      1      0      1      0      1      1  \n",
       "\n",
       "[45532 rows x 55 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data train에 필요없는 voted,index familysize제거(familysize는 outlier가 많음)\n",
    "data_train=train_csv.drop(['voted','index','familysize'],axis=1)\n",
    "\n",
    "# QaE등 문제를 푸는데 드는 시간값 제거\n",
    "rd=[]\n",
    "for i in range(1,40,2):\n",
    "    print(data_train.columns[i])\n",
    "    rd.append(data_train.columns[i])\n",
    "    \n",
    "for a in rd:\n",
    "    data_train=data_train.drop(['{}'.format(a)],axis=1)\n",
    "    \n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QaA: [3. 5. 4. 1. 2.]\n",
      "QbA: [4. 5. 1. 3. 2.]\n",
      "QcA: [5. 3. 1. 4. 2.]\n",
      "QdA: [1. 5. 4. 3. 2.]\n",
      "QeA: [2. 1. 5. 4. 3.]\n",
      "QfA: [5. 3. 1. 2. 4.]\n",
      "QgA: [2. 1. 4. 5. 3.]\n",
      "QhA: [4. 1. 3. 5. 2.]\n",
      "QiA: [5. 3. 1. 2. 4.]\n",
      "QjA: [4. 3. 2. 5. 1.]\n",
      "QkA: [4. 5. 3. 1. 2.]\n",
      "QlA: [4. 5. 1. 3. 2.]\n",
      "QmA: [2. 1. 4. 3. 5.]\n",
      "QnA: [5. 4. 2. 3. 1.]\n",
      "QoA: [2. 1. 4. 5. 3.]\n",
      "QpA: [2. 5. 1. 4. 3.]\n",
      "QqA: [2. 5. 3. 4. 1.]\n",
      "QrA: [2. 1. 4. 5. 3.]\n",
      "QsA: [2. 4. 1. 3. 5.]\n",
      "QtA: [1. 5. 2. 3. 4.]\n",
      "age_group: ['30s' '20s' '40s' '50s' '10s' '60s' '+70s']\n",
      "education: [2 4 3 1 0]\n",
      "engnat: [1 2 0]\n",
      "gender: ['Female' 'Male']\n",
      "hand: [1 2 3 0]\n",
      "married: [3 1 2 0]\n",
      "race: ['White' 'Asian' 'Other' 'Black' 'Native American' 'Arab'\n",
      " 'Indigenous Australian']\n",
      "religion: ['Other' 'Hindu' 'Agnostic' 'Atheist' 'Christian_Other'\n",
      " 'Christian_Catholic' 'Muslim' 'Buddhist' 'Christian_Protestant' 'Jewish'\n",
      " 'Christian_Mormon' 'Sikh']\n",
      "tp01: [2 1 5 3 0 4 6 7]\n",
      "tp02: [2 1 3 4 5 6 0 7]\n",
      "tp03: [2 0 1 5 3 4 6 7]\n",
      "tp04: [1 0 5 6 4 2 3 7]\n",
      "tp05: [2 1 3 0 5 4 6 7]\n",
      "tp06: [1 2 4 3 0 5 6 7]\n",
      "tp07: [7 3 2 1 0 5 4 6]\n",
      "tp08: [4 6 3 7 2 1 5 0]\n",
      "tp09: [4 0 1 2 5 3 6 7]\n",
      "tp10: [3 4 6 5 1 2 0 7]\n",
      "urban: [1 3 2 0]\n",
      "wf_01: [0 1]\n",
      "wf_02: [0 1]\n",
      "wf_03: [0 1]\n",
      "wr_01: [0 1]\n",
      "wr_02: [1 0]\n",
      "wr_03: [0 1]\n",
      "wr_04: [0 1]\n",
      "wr_05: [1 0]\n",
      "wr_06: [0 1]\n",
      "wr_07: [1 0]\n",
      "wr_08: [1 0]\n",
      "wr_09: [0 1]\n",
      "wr_10: [1 0]\n",
      "wr_11: [0 1]\n",
      "wr_12: [1 0]\n",
      "wr_13: [1 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_train.columns)):\n",
    "    print(data_train.columns[i], data_train[data_train.columns[i]].unique(),sep=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder를 통해 columns에 대한 모든 unique값을 onehotencoding함\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe=OneHotEncoder()\n",
    "\n",
    "data_train_ohe=ohe.fit_transform(data_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 1., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 0., 1., ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voted는 target변수로 1열로 reshape함\n",
    "\n",
    "target=train_csv['voted']\n",
    "target_num=target.to_numpy()\n",
    "target_num=target_num.reshape(target.count(),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험용 데이터로 측정한 정확도 = 0.68\n"
     ]
    }
   ],
   "source": [
    "# train값을 trian,test로 나누어 먼저 정확도 측정\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(data_train_ohe, target_num, test_size=0.2)\n",
    "\n",
    "svm = SVC(kernel='rbf',C=10,gamma=0.1,random_state=0)\n",
    "svm.fit(trainX, trainY)\n",
    "\n",
    "print('시험용 데이터로 측정한 정확도 = %.2f' % svm.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>736</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2941</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1952</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1552</td>\n",
       "      <td>3.0</td>\n",
       "      <td>821</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2507</td>\n",
       "      <td>4.0</td>\n",
       "      <td>480</td>\n",
       "      <td>2.0</td>\n",
       "      <td>614</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1243</td>\n",
       "      <td>5.0</td>\n",
       "      <td>845</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1666</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  QaA  QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA  ...  wr_04  wr_05  \\\n",
       "0      0  3.0  736  2.0  2941  3.0  4621  1.0  4857  2.0  ...      0      1   \n",
       "1      1  3.0  514  2.0  1952  3.0  1552  3.0   821  4.0  ...      0      0   \n",
       "2      2  3.0  500  2.0  2507  4.0   480  2.0   614  2.0  ...      0      1   \n",
       "3      3  1.0  669  1.0  1050  5.0  1435  2.0  2252  5.0  ...      1      1   \n",
       "4      4  2.0  499  1.0  1243  5.0   845  2.0  1666  2.0  ...      1      1   \n",
       "\n",
       "   wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "0      0      0      1      0      1      0      1      1  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      1      1      0      1      0      1      1  \n",
       "3      1      1      1      1      1      1      1      1  \n",
       "4      0      1      1      0      1      1      1      1  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv= pd.read_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/input/test_x.csv')\n",
    "test_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QaA</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QeA</th>\n",
       "      <th>QfA</th>\n",
       "      <th>QgA</th>\n",
       "      <th>QhA</th>\n",
       "      <th>QiA</th>\n",
       "      <th>QjA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11378</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11383 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QaA  QbA  QcA  QdA  QeA  QfA  QgA  QhA  QiA  QjA  ...  wr_04  wr_05  \\\n",
       "0      3.0  2.0  3.0  1.0  2.0  4.0  5.0  2.0  4.0  2.0  ...      0      1   \n",
       "1      3.0  2.0  3.0  3.0  4.0  1.0  2.0  1.0  5.0  3.0  ...      0      0   \n",
       "2      3.0  2.0  4.0  2.0  2.0  2.0  1.0  1.0  2.0  4.0  ...      0      1   \n",
       "3      1.0  1.0  5.0  2.0  5.0  1.0  1.0  1.0  1.0  1.0  ...      1      1   \n",
       "4      2.0  1.0  5.0  2.0  2.0  2.0  5.0  1.0  2.0  3.0  ...      1      1   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "11378  5.0  5.0  5.0  1.0  2.0  2.0  4.0  1.0  3.0  4.0  ...      1      1   \n",
       "11379  1.0  5.0  5.0  1.0  2.0  1.0  1.0  1.0  1.0  5.0  ...      1      1   \n",
       "11380  1.0  2.0  1.0  2.0  1.0  2.0  2.0  4.0  4.0  2.0  ...      1      1   \n",
       "11381  2.0  1.0  2.0  1.0  2.0  1.0  4.0  1.0  1.0  2.0  ...      1      0   \n",
       "11382  2.0  4.0  5.0  2.0  1.0  4.0  2.0  4.0  4.0  5.0  ...      0      0   \n",
       "\n",
       "       wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "0          0      0      1      0      1      0      1      1  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      1      1      0      1      0      1      1  \n",
       "3          1      1      1      1      1      1      1      1  \n",
       "4          0      1      1      0      1      1      1      1  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "11378      0      1      1      0      1      0      1      1  \n",
       "11379      1      1      1      1      1      1      1      1  \n",
       "11380      0      1      1      0      1      0      1      1  \n",
       "11381      0      1      1      0      1      1      1      0  \n",
       "11382      1      0      1      0      0      1      0      0  \n",
       "\n",
       "[11383 rows x 55 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data또한 필요없는 값은 indexdhk familysize 및 QaE등 시간 데이터 제거 \n",
    "\n",
    "data_test=test_csv.drop(['index','familysize'],axis=1)\n",
    "for a in rd:\n",
    "    data_test=data_test.drop(['{}'.format(a)],axis=1)\n",
    "    \n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QaA: [3. 1. 2. 4. 5.]\n",
      "QbA: [2. 1. 5. 4. 3.]\n",
      "QcA: [3. 4. 5. 2. 1.]\n",
      "QdA: [1. 3. 2. 5. 4.]\n",
      "QeA: [2. 4. 5. 3. 1.]\n",
      "QfA: [4. 1. 2. 5. 3.]\n",
      "QgA: [5. 2. 1. 4. 3.]\n",
      "QhA: [2. 1. 5. 4. 3.]\n",
      "QiA: [4. 5. 2. 1. 3.]\n",
      "QjA: [2. 3. 4. 1. 5.]\n",
      "QkA: [5. 4. 3. 1. 2.]\n",
      "QlA: [3. 5. 4. 2. 1.]\n",
      "QmA: [3. 4. 2. 5. 1.]\n",
      "QnA: [5. 1. 2. 4. 3.]\n",
      "QoA: [3. 2. 5. 4. 1.]\n",
      "QpA: [4. 3. 5. 2. 1.]\n",
      "QqA: [3. 4. 5. 2. 1.]\n",
      "QrA: [4. 5. 1. 2. 3.]\n",
      "QsA: [1. 3. 4. 5. 2.]\n",
      "QtA: [2. 4. 5. 1. 3.]\n",
      "age_group: ['10s' '30s' '60s' '20s' '50s' '40s' '+70s']\n",
      "education: [2 3 4 1 0]\n",
      "engnat: [2 1 0]\n",
      "gender: ['Male' 'Female']\n",
      "hand: [1 2 3 0]\n",
      "married: [1 2 3 0]\n",
      "race: ['White' 'Other' 'Asian' 'Native American' 'Arab' 'Black'\n",
      " 'Indigenous Australian']\n",
      "religion: ['Christian_Protestant' 'Christian_Catholic' 'Christian_Other' 'Agnostic'\n",
      " 'Buddhist' 'Hindu' 'Other' 'Atheist' 'Sikh' 'Muslim' 'Christian_Mormon'\n",
      " 'Jewish']\n",
      "tp01: [2 7 6 0 1 5 4 3]\n",
      "tp02: [1 7 2 5 0 3 4 6]\n",
      "tp03: [1 7 3 2 0 4 5 6]\n",
      "tp04: [4 7 0 6 2 3 1 5]\n",
      "tp05: [1 7 6 0 3 2 5 4]\n",
      "tp06: [2 7 1 6 0 5 3 4]\n",
      "tp07: [2 7 0 5 1 4 3 6]\n",
      "tp08: [3 7 2 5 6 1 0 4]\n",
      "tp09: [4 7 1 0 2 5 3 6]\n",
      "tp10: [4 7 1 6 3 2 5 0]\n",
      "urban: [2 3 1 0]\n",
      "wf_01: [0 1]\n",
      "wf_02: [0 1]\n",
      "wf_03: [0 1]\n",
      "wr_01: [0 1]\n",
      "wr_02: [1 0]\n",
      "wr_03: [0 1]\n",
      "wr_04: [0 1]\n",
      "wr_05: [1 0]\n",
      "wr_06: [0 1]\n",
      "wr_07: [0 1]\n",
      "wr_08: [1 0]\n",
      "wr_09: [0 1]\n",
      "wr_10: [1 0]\n",
      "wr_11: [0 1]\n",
      "wr_12: [1 0]\n",
      "wr_13: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# train과 test데이터가 같은 columns과 unique값을 갖는지 확인\n",
    "\n",
    "for i in range(len(data_test.columns)):\n",
    "    print(data_test.columns[i], data_test[data_test.columns[i]].unique(),sep=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_ohe=ohe.fit_transform(data_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45532, 260)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy 배열을 보며 onehotencoding된 train와 test가 훈련 가능한 같은 형태 인지 확인\n",
    "# target과 train의 데이터 수가 같은지 확인\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.shape(data_train_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45532, 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(target_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11383, 260)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "svm_real = SVC(kernel='rbf',C=10,gamma=0.1,random_state=0)\n",
    "svm_real.fit(data_train_ohe,target_num)\n",
    "\n",
    "test_pred=svm_real.predict(data_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11378</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11383 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       voted\n",
       "index       \n",
       "0          2\n",
       "1          2\n",
       "2          1\n",
       "3          1\n",
       "4          2\n",
       "...      ...\n",
       "11378      1\n",
       "11379      2\n",
       "11380      1\n",
       "11381      1\n",
       "11382      2\n",
       "\n",
       "[11383 rows x 1 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df=pd.DataFrame(test_pred)\n",
    "test_pred_df.columns=['voted']\n",
    "test_pred_df['index']=test_pred_df.index\n",
    "test_pred_df=test_pred_df.set_index('index')\n",
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.to_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/test_prediction_OHE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# C, gamma값을 바꾸며 정확도 확인\n",
    "\n",
    "svm_real2 = SVC(kernel='rbf',C=50,gamma=0.1,random_state=0)\n",
    "svm_real2.fit(data_train_ohe,target_num)\n",
    "\n",
    "test_pred2=svm_real2.predict(data_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2_df=pd.DataFrame(test_pred2)\n",
    "test_pred2_df.columns=['voted']\n",
    "test_pred2_df['index']=test_pred2_df.index\n",
    "test_pred2_df=test_pred2_df.set_index('index')\n",
    "test_pred2_df\n",
    "\n",
    "test_pred2_df.to_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/test_prediction_OHE2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "svm_real3 = SVC(kernel='rbf',C=10,gamma=10,random_state=0)\n",
    "svm_real3.fit(data_train_ohe,target_num)\n",
    "\n",
    "test_pred3=svm_real3.predict(data_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred3_df=pd.DataFrame(test_pred3)\n",
    "test_pred3_df.columns=['voted']\n",
    "test_pred3_df['index']=test_pred3_df.index\n",
    "test_pred3_df=test_pred3_df.set_index('index')\n",
    "test_pred3_df\n",
    "\n",
    "test_pred3_df.to_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/test_prediction_OHE3.csv')"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 svm훈련에 대한 test 결과\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험용 데이터로 측정한 정확도 = 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(trainX, trainY)\n",
    "\n",
    "print('시험용 데이터로 측정한 정확도 = %.2f' % knn.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "knn_real = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_real.fit(data_train_ohe,target_num)\n",
    "\n",
    "knn_pred=knn_real.predict(data_test_ohe)\n",
    "\n",
    "knn_pred_df=pd.DataFrame(knn_pred)\n",
    "knn_pred_df.columns=['voted']\n",
    "knn_pred_df['index']=knn_pred_df.index\n",
    "knn_pred_df=knn_pred_df.set_index('index')\n",
    "\n",
    "knn_pred_df.to_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/test_prediction_KNN.csv')"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN훈련에 대한 test결과\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험용 데이터로 측정한 정확도 = 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(trainX,trainY)\n",
    "print('시험용 데이터로 측정한 정확도 = %.2f' % nb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "nb_real = GaussianNB()\n",
    "nb_real.fit(data_train_ohe,target_num)\n",
    "\n",
    "nb_pred=nb_real.predict(data_test_ohe)\n",
    "\n",
    "nb_pred_df=pd.DataFrame(nb_pred)\n",
    "nb_pred_df.columns=['voted']\n",
    "nb_pred_df['index']=nb_pred_df.index\n",
    "nb_pred_df=nb_pred_df.set_index('index')\n",
    "\n",
    "nb_pred_df.to_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/test_prediction_NB.csv')"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes에 대한 test결과\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험용 데이터로 측정한 정확도 = 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree=DecisionTreeClassifier(random_state=0)\n",
    "dtree.fit(trainX, trainY)\n",
    "\n",
    "print('시험용 데이터로 측정한 정확도 = %.2f' % dtree.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.58596197e-03, 3.27692105e-03, 5.35749528e-03, 3.64477538e-03,\n",
       "       2.55824951e-03, 4.11505979e-03, 4.11431210e-03, 2.77510356e-03,\n",
       "       3.33782759e-03, 4.42663895e-03, 3.55076403e-03, 4.22042547e-03,\n",
       "       1.91249412e-03, 5.88220508e-03, 5.10819732e-03, 4.32068532e-03,\n",
       "       2.76413669e-03, 3.70848616e-03, 2.34712953e-03, 1.21518862e-03,\n",
       "       4.39623532e-03, 6.31790411e-03, 3.01788484e-03, 4.29758649e-03,\n",
       "       3.75330778e-03, 3.55813881e-03, 3.46808267e-03, 2.36969569e-03,\n",
       "       3.87216192e-03, 3.01917979e-03, 4.12993267e-03, 5.22744511e-03,\n",
       "       3.20274008e-03, 4.96001069e-03, 4.79718628e-03, 4.36004625e-03,\n",
       "       3.95973285e-03, 3.64111013e-03, 4.99335612e-03, 3.27592884e-03,\n",
       "       3.55897822e-03, 5.32251477e-03, 2.99620316e-03, 3.73321198e-03,\n",
       "       3.52411627e-03, 2.55341637e-03, 3.72373946e-03, 2.22471538e-03,\n",
       "       5.04543174e-03, 3.60429021e-03, 2.93027888e-03, 4.51284909e-03,\n",
       "       3.02710603e-03, 3.68995101e-03, 2.95585488e-03, 3.42078725e-03,\n",
       "       2.07259763e-03, 3.32793298e-03, 3.32764368e-03, 2.83753320e-03,\n",
       "       3.04209158e-03, 2.85395537e-03, 2.83473179e-03, 6.25205331e-03,\n",
       "       3.60672201e-03, 3.43534546e-03, 3.37331439e-03, 2.69738644e-03,\n",
       "       4.45548394e-03, 4.32486636e-03, 3.26560420e-03, 3.32238590e-03,\n",
       "       3.13350310e-03, 4.88287322e-03, 3.52468859e-03, 4.41058190e-03,\n",
       "       3.24315402e-03, 4.00028748e-03, 4.28665053e-03, 4.58721893e-03,\n",
       "       2.77129400e-03, 2.54773426e-03, 3.87641913e-03, 4.46750253e-03,\n",
       "       3.49359091e-03, 3.53872439e-03, 4.69060924e-03, 2.79309073e-03,\n",
       "       5.93201207e-03, 4.12604207e-03, 3.14934287e-03, 2.11508953e-03,\n",
       "       3.42855687e-03, 4.08532989e-03, 3.22469354e-03, 2.94874221e-03,\n",
       "       4.34790912e-03, 4.31925439e-03, 4.25121818e-03, 4.73184691e-03,\n",
       "       1.07530051e-03, 1.57250706e-01, 6.48790355e-03, 2.17883860e-03,\n",
       "       3.14562674e-03, 2.90097109e-03, 1.30997876e-03, 7.73352618e-04,\n",
       "       1.54230280e-02, 5.54478770e-03, 8.25156835e-03, 3.37926742e-03,\n",
       "       3.62997887e-04, 1.31756034e-03, 6.39305144e-03, 2.75500301e-03,\n",
       "       4.46957112e-03, 1.99430418e-04, 3.99128652e-03, 3.69982759e-03,\n",
       "       1.76326121e-03, 3.26705672e-04, 1.50051259e-03, 7.03631161e-03,\n",
       "       1.45663892e-03, 4.38408876e-04, 4.44357396e-03, 1.06619173e-03,\n",
       "       3.82048078e-04, 7.69639739e-04, 1.20744588e-03, 1.45387095e-02,\n",
       "       5.79612427e-03, 4.43201782e-03, 1.90474718e-03, 4.22008088e-03,\n",
       "       7.58902942e-04, 2.97161805e-03, 3.26938255e-03, 8.49631811e-04,\n",
       "       1.21003776e-03, 7.21668561e-04, 4.97831043e-03, 2.30093958e-04,\n",
       "       3.26821665e-03, 4.24620348e-03, 4.92425541e-03, 4.35887900e-03,\n",
       "       4.26053915e-03, 4.05671072e-03, 4.96702328e-03, 9.65678481e-05,\n",
       "       4.72356890e-03, 3.94520216e-03, 4.98895602e-03, 2.13378498e-03,\n",
       "       3.08322366e-03, 3.70066165e-03, 4.82776372e-03, 5.50407108e-04,\n",
       "       3.90070810e-03, 3.81034333e-03, 5.05329248e-03, 2.71439900e-03,\n",
       "       3.92168505e-03, 2.36117666e-03, 1.61882658e-03, 4.54199759e-04,\n",
       "       3.29820415e-03, 3.32843314e-03, 4.04589828e-03, 2.96991316e-03,\n",
       "       3.15064322e-03, 4.62441690e-03, 4.64471565e-03, 1.89073390e-04,\n",
       "       5.30070927e-03, 5.25484431e-03, 4.31098316e-03, 2.76699584e-03,\n",
       "       3.24078063e-03, 1.76502851e-03, 6.33559533e-04, 1.40788872e-04,\n",
       "       4.06534840e-03, 5.92625703e-03, 4.60143806e-03, 3.96964068e-03,\n",
       "       4.00167284e-03, 4.28219932e-03, 2.81810429e-03, 2.45017654e-04,\n",
       "       3.79469171e-03, 3.44046261e-03, 3.34028145e-03, 4.17149578e-03,\n",
       "       2.91212642e-03, 2.95826635e-03, 1.50984134e-03, 5.21614555e-04,\n",
       "       2.85949547e-03, 4.47478864e-03, 5.20187076e-03, 3.61445084e-03,\n",
       "       4.00478178e-03, 3.37377376e-03, 5.00146420e-03, 1.55119665e-04,\n",
       "       2.62959610e-03, 5.18565755e-03, 4.03257105e-03, 3.50096838e-03,\n",
       "       4.07734024e-03, 2.86233183e-03, 2.90828984e-03, 4.46411982e-04,\n",
       "       2.29386421e-03, 2.91964278e-03, 3.90901841e-03, 3.41280411e-03,\n",
       "       4.20500371e-03, 3.65943003e-03, 3.99130255e-03, 1.03470418e-04,\n",
       "       5.95841509e-04, 5.11448024e-03, 4.98120804e-03, 4.19956935e-03,\n",
       "       2.57182981e-03, 1.42838952e-03, 1.94152570e-03, 2.57538719e-03,\n",
       "       2.19737428e-03, 1.67644790e-03, 1.48988796e-03, 2.59463665e-03,\n",
       "       1.35472525e-03, 1.19979111e-03, 2.15083554e-03, 1.98128959e-03,\n",
       "       1.98213211e-03, 1.44972410e-03, 9.25816419e-04, 9.69940021e-04,\n",
       "       2.11446583e-03, 2.84188586e-03, 1.92441561e-03, 7.29799954e-04,\n",
       "       2.88023914e-04, 5.12237549e-04, 2.73995237e-03, 2.86116937e-03,\n",
       "       4.69200148e-04, 8.94439428e-04, 3.09996857e-03, 3.03170641e-03,\n",
       "       1.40750377e-03, 4.79299179e-04, 5.36282598e-04, 8.92428720e-04])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어떤 feature의 결정도가 높은지 확인\n",
    "\n",
    "dtree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_real = DecisionTreeClassifier(random_state=0)\n",
    "dtree_real.fit(data_train_ohe,target_num)\n",
    "\n",
    "dtree_pred=nb_real.predict(data_test_ohe)\n",
    "\n",
    "dtree_pred_df=pd.DataFrame(dtree_pred)\n",
    "dtree_pred_df.columns=['voted']\n",
    "dtree_pred_df['index']=dtree_pred_df.index\n",
    "dtree_pred_df=dtree_pred_df.set_index('index')\n",
    "\n",
    "dtree_pred_df.to_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/test_prediction_DecisionTree.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36425 samples\n",
      "Epoch 1/100\n",
      "36425/36425 [==============================] - 91s 3ms/sample - loss: -133081.9039 - binary_accuracy: 0.4528\n",
      "Epoch 2/100\n",
      "36425/36425 [==============================] - 92s 3ms/sample - loss: -399379.6738 - binary_accuracy: 0.4528\n",
      "Epoch 3/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -665677.0888 - binary_accuracy: 0.4528\n",
      "Epoch 4/100\n",
      "36425/36425 [==============================] - 96s 3ms/sample - loss: -931974.6984 - binary_accuracy: 0.4528\n",
      "Epoch 5/100\n",
      "36425/36425 [==============================] - 97s 3ms/sample - loss: -1198272.4358 - binary_accuracy: 0.4528\n",
      "Epoch 6/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -1464569.0083 - binary_accuracy: 0.4528\n",
      "Epoch 7/100\n",
      "36425/36425 [==============================] - 89s 2ms/sample - loss: -1730865.4954 - binary_accuracy: 0.4528\n",
      "Epoch 8/100\n",
      "36425/36425 [==============================] - 99s 3ms/sample - loss: -1997161.7043 - binary_accuracy: 0.4528\n",
      "Epoch 9/100\n",
      "36425/36425 [==============================] - 91s 3ms/sample - loss: -2263459.0025 - binary_accuracy: 0.4528\n",
      "Epoch 10/100\n",
      "36425/36425 [==============================] - 92s 3ms/sample - loss: -2529757.1117 - binary_accuracy: 0.4528\n",
      "Epoch 11/100\n",
      "36425/36425 [==============================] - 95s 3ms/sample - loss: -2796055.6373 - binary_accuracy: 0.4528\n",
      "Epoch 12/100\n",
      "36425/36425 [==============================] - 93s 3ms/sample - loss: -3062353.6577 - binary_accuracy: 0.4528\n",
      "Epoch 13/100\n",
      "36425/36425 [==============================] - 90s 2ms/sample - loss: -3328651.6314 - binary_accuracy: 0.4528\n",
      "Epoch 14/100\n",
      "36425/36425 [==============================] - 90s 2ms/sample - loss: -3594950.4426 - binary_accuracy: 0.4528\n",
      "Epoch 15/100\n",
      "36425/36425 [==============================] - 94s 3ms/sample - loss: -3861248.8360 - binary_accuracy: 0.4528\n",
      "Epoch 16/100\n",
      "36425/36425 [==============================] - 91s 3ms/sample - loss: -4127547.8655 - binary_accuracy: 0.4528\n",
      "Epoch 17/100\n",
      "36425/36425 [==============================] - 94s 3ms/sample - loss: -4393850.5808 - binary_accuracy: 0.4528\n",
      "Epoch 18/100\n",
      "36425/36425 [==============================] - 92s 3ms/sample - loss: -4660151.9749 - binary_accuracy: 0.4528\n",
      "Epoch 19/100\n",
      "36425/36425 [==============================] - 91s 3ms/sample - loss: -4926452.1990 - binary_accuracy: 0.4528\n",
      "Epoch 20/100\n",
      "36425/36425 [==============================] - 91s 3ms/sample - loss: -5192752.2966 - binary_accuracy: 0.4528\n",
      "Epoch 21/100\n",
      "36425/36425 [==============================] - 101s 3ms/sample - loss: -5459051.7218 - binary_accuracy: 0.4528\n",
      "Epoch 22/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -5725350.6857 - binary_accuracy: 0.4528\n",
      "Epoch 23/100\n",
      "36425/36425 [==============================] - 104s 3ms/sample - loss: -5991648.6744 - binary_accuracy: 0.4528\n",
      "Epoch 24/100\n",
      "36425/36425 [==============================] - 98s 3ms/sample - loss: -6257946.5072 - binary_accuracy: 0.4528\n",
      "Epoch 25/100\n",
      "36425/36425 [==============================] - 104s 3ms/sample - loss: -6524243.8013 - binary_accuracy: 0.4528\n",
      "Epoch 26/100\n",
      "36425/36425 [==============================] - 92s 3ms/sample - loss: -6790539.4807 - binary_accuracy: 0.4528\n",
      "Epoch 27/100\n",
      "36425/36425 [==============================] - 92s 3ms/sample - loss: -7056834.1357 - binary_accuracy: 0.4528\n",
      "Epoch 28/100\n",
      "36425/36425 [==============================] - 95s 3ms/sample - loss: -7323127.1106 - binary_accuracy: 0.4528\n",
      "Epoch 29/100\n",
      "36425/36425 [==============================] - 87s 2ms/sample - loss: -7589417.4321 - binary_accuracy: 0.4528\n",
      "Epoch 30/100\n",
      "36425/36425 [==============================] - 103s 3ms/sample - loss: -7855703.5641 - binary_accuracy: 0.4528\n",
      "Epoch 31/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -8121987.8042 - binary_accuracy: 0.4528\n",
      "Epoch 32/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -8388264.1046 - binary_accuracy: 0.4528\n",
      "Epoch 33/100\n",
      "36425/36425 [==============================] - 92s 3ms/sample - loss: -8654538.6269 - binary_accuracy: 0.4528\n",
      "Epoch 34/100\n",
      "36425/36425 [==============================] - 96s 3ms/sample - loss: -8920813.3589 - binary_accuracy: 0.4528\n",
      "Epoch 35/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -9187086.8702 - binary_accuracy: 0.4528\n",
      "Epoch 36/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -9453358.9931 - binary_accuracy: 0.4528\n",
      "Epoch 37/100\n",
      "36425/36425 [==============================] - 97s 3ms/sample - loss: -9719630.0906 - binary_accuracy: 0.4528\n",
      "Epoch 38/100\n",
      "36425/36425 [==============================] - 88s 2ms/sample - loss: -9985899.3955 - binary_accuracy: 0.4528\n",
      "Epoch 39/100\n",
      "36425/36425 [==============================] - 90s 2ms/sample - loss: -10252167.3926 - binary_accuracy: 0.4528- ETA: 1s - loss: -10252906.5006 - binary_accuracy: 0.45 - ETA: 1s - loss: -10254469.\n",
      "Epoch 40/100\n",
      "36425/36425 [==============================] - 596s 16ms/sample - loss: -10518433.0691 - binary_accuracy: 0.4528\n",
      "Epoch 41/100\n",
      "36425/36425 [==============================] - 130s 4ms/sample - loss: -10784696.8372 - binary_accuracy: 0.4528\n",
      "Epoch 42/100\n",
      "36425/36425 [==============================] - 126s 3ms/sample - loss: -11050958.2130 - binary_accuracy: 0.4528\n",
      "Epoch 43/100\n",
      "36425/36425 [==============================] - 128s 4ms/sample - loss: -11317217.0165 - binary_accuracy: 0.4528\n",
      "Epoch 44/100\n",
      "36425/36425 [==============================] - 110s 3ms/sample - loss: -11583476.4507 - binary_accuracy: 0.4528\n",
      "Epoch 45/100\n",
      "36425/36425 [==============================] - 92s 3ms/sample - loss: -11849735.1570 - binary_accuracy: 0.4528\n",
      "Epoch 46/100\n",
      "36425/36425 [==============================] - 87s 2ms/sample - loss: -12115993.4196 - binary_accuracy: 0.4528\n",
      "Epoch 47/100\n",
      "36425/36425 [==============================] - 89s 2ms/sample - loss: -12382250.1144 - binary_accuracy: 0.4528\n",
      "Epoch 48/100\n",
      "36425/36425 [==============================] - 94s 3ms/sample - loss: -12648504.6245 - binary_accuracy: 0.4528\n",
      "Epoch 49/100\n",
      "36425/36425 [==============================] - 102s 3ms/sample - loss: -12914757.2718 - binary_accuracy: 0.4528\n",
      "Epoch 50/100\n",
      "36425/36425 [==============================] - 105s 3ms/sample - loss: -13181008.6928 - binary_accuracy: 0.4528\n",
      "Epoch 51/100\n",
      "36425/36425 [==============================] - 124s 3ms/sample - loss: -13447258.6565 - binary_accuracy: 0.4528\n",
      "Epoch 52/100\n",
      "36425/36425 [==============================] - 101s 3ms/sample - loss: -13713506.8538 - binary_accuracy: 0.4528\n",
      "Epoch 53/100\n",
      "36425/36425 [==============================] - 88s 2ms/sample - loss: -13979753.3796 - binary_accuracy: 0.4528\n",
      "Epoch 54/100\n",
      "36425/36425 [==============================] - 87s 2ms/sample - loss: -14246002.7050 - binary_accuracy: 0.4528\n",
      "Epoch 55/100\n",
      "36425/36425 [==============================] - 134s 4ms/sample - loss: -14512250.2275 - binary_accuracy: 0.4528\n",
      "Epoch 56/100\n",
      "36425/36425 [==============================] - 151s 4ms/sample - loss: -14778495.1973 - binary_accuracy: 0.4528\n",
      "Epoch 57/100\n",
      "36425/36425 [==============================] - 129s 4ms/sample - loss: -15044730.9794 - binary_accuracy: 0.4528\n",
      "Epoch 58/100\n",
      "36425/36425 [==============================] - 147s 4ms/sample - loss: -15310955.4630 - binary_accuracy: 0.4528\n",
      "Epoch 59/100\n",
      "36425/36425 [==============================] - 150s 4ms/sample - loss: -15577180.6777 - binary_accuracy: 0.4528\n",
      "Epoch 60/100\n",
      "36425/36425 [==============================] - 150s 4ms/sample - loss: -15843404.0712 - binary_accuracy: 0.4528\n",
      "Epoch 61/100\n",
      "36425/36425 [==============================] - 151s 4ms/sample - loss: -16109621.9826 - binary_accuracy: 0.4528\n",
      "Epoch 62/100\n",
      "36425/36425 [==============================] - 146s 4ms/sample - loss: -16375839.5293 - binary_accuracy: 0.4528\n",
      "Epoch 63/100\n",
      "36425/36425 [==============================] - 150s 4ms/sample - loss: -16642056.1174 - binary_accuracy: 0.4528\n",
      "Epoch 64/100\n",
      "36425/36425 [==============================] - 151s 4ms/sample - loss: -16908268.7571 - binary_accuracy: 0.4528\n",
      "Epoch 65/100\n",
      "36425/36425 [==============================] - 150s 4ms/sample - loss: -17174478.4370 - binary_accuracy: 0.4528\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36425/36425 [==============================] - 149s 4ms/sample - loss: -17440686.6552 - binary_accuracy: 0.4528\n",
      "Epoch 67/100\n",
      "36425/36425 [==============================] - 150s 4ms/sample - loss: -17706893.3023 - binary_accuracy: 0.4528\n",
      "Epoch 68/100\n",
      "36425/36425 [==============================] - 150s 4ms/sample - loss: -17973095.6162 - binary_accuracy: 0.4528\n",
      "Epoch 69/100\n",
      "36425/36425 [==============================] - 151s 4ms/sample - loss: -18239294.5101 - binary_accuracy: 0.4528\n",
      "Epoch 70/100\n",
      "36425/36425 [==============================] - 113s 3ms/sample - loss: -18505487.8262 - binary_accuracy: 0.4528\n",
      "Epoch 71/100\n",
      "36425/36425 [==============================] - 81s 2ms/sample - loss: -18771678.7762 - binary_accuracy: 0.4528\n",
      "Epoch 72/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -19037869.0873 - binary_accuracy: 0.4528\n",
      "Epoch 73/100\n",
      "36425/36425 [==============================] - 81s 2ms/sample - loss: -19304056.9463 - binary_accuracy: 0.4528\n",
      "Epoch 74/100\n",
      "36425/36425 [==============================] - 81s 2ms/sample - loss: -19570242.4197 - binary_accuracy: 0.4528\n",
      "Epoch 75/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -19836429.6578 - binary_accuracy: 0.4528\n",
      "Epoch 76/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -20102615.3061 - binary_accuracy: 0.4528\n",
      "Epoch 77/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -20368798.5876 - binary_accuracy: 0.4528\n",
      "Epoch 78/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -20634979.7195 - binary_accuracy: 0.4528\n",
      "Epoch 79/100\n",
      "36425/36425 [==============================] - 86s 2ms/sample - loss: -20901160.4995 - binary_accuracy: 0.4528\n",
      "Epoch 80/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -21167339.9763 - binary_accuracy: 0.4528\n",
      "Epoch 81/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -21433514.7471 - binary_accuracy: 0.4528\n",
      "Epoch 82/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -21699685.9590 - binary_accuracy: 0.4528\n",
      "Epoch 83/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -21965854.6432 - binary_accuracy: 0.4528\n",
      "Epoch 84/100\n",
      "36425/36425 [==============================] - 85s 2ms/sample - loss: -22232019.6188 - binary_accuracy: 0.4528\n",
      "Epoch 85/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -22498181.0213 - binary_accuracy: 0.4528\n",
      "Epoch 86/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -22764339.1967 - binary_accuracy: 0.4528\n",
      "Epoch 87/100\n",
      "36425/36425 [==============================] - 81s 2ms/sample - loss: -23030494.5795 - binary_accuracy: 0.4528\n",
      "Epoch 88/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -23296648.0585 - binary_accuracy: 0.4528\n",
      "Epoch 89/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -23562800.7480 - binary_accuracy: 0.4528\n",
      "Epoch 90/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -23828953.3830 - binary_accuracy: 0.4528\n",
      "Epoch 91/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -24095104.1027 - binary_accuracy: 0.4528\n",
      "Epoch 92/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -24361253.7478 - binary_accuracy: 0.4528\n",
      "Epoch 93/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -24627401.5658 - binary_accuracy: 0.4528\n",
      "Epoch 94/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -24893544.3514 - binary_accuracy: 0.4528\n",
      "Epoch 95/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -25159686.0323 - binary_accuracy: 0.4528\n",
      "Epoch 96/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -25425824.4312 - binary_accuracy: 0.4528\n",
      "Epoch 97/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -25691959.6190 - binary_accuracy: 0.4528\n",
      "Epoch 98/100\n",
      "36425/36425 [==============================] - 59s 2ms/sample - loss: -25958092.6921 - binary_accuracy: 0.45280s - loss: -25968273.5017 - binary_accuracy: 0.45\n",
      "Epoch 99/100\n",
      "36425/36425 [==============================] - 27s 732us/sample - loss: -26224221.5241 - binary_accuracy: 0.4528 - loss: -26233 - ETA: 0s - loss: -26241042.6564 - binary_accuracy:\n",
      "Epoch 100/100\n",
      "36425/36425 [==============================] - 27s 731us/sample - loss: -26490347.1025 - binary_accuracy: 0.4528 - loss: -26447 - ETA: 2s - loss: -26493146.1859 - binary_accuracy: 0.452 - ETA: 2s - loss: -26492528.0241 - binary_accuracy: 0.452 - ETA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a53ac0c48>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
    "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=260, activation='sigmoid'))\n",
    "sgd=optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd ,loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(trainX,trainY, batch_size=1, epochs=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36425 samples\n",
      "Epoch 1/100\n",
      "36425/36425 [==============================] - 108s 3ms/sample - loss: -8.3359 - binary_accuracy: 0.4527\n",
      "Epoch 2/100\n",
      "36425/36425 [==============================] - 113s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 3/100\n",
      "36425/36425 [==============================] - 114s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 4/100\n",
      "36425/36425 [==============================] - 102s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 5/100\n",
      "36425/36425 [==============================] - 101s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 6/100\n",
      "36425/36425 [==============================] - 98s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 7/100\n",
      "36425/36425 [==============================] - 97s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 8/100\n",
      "36425/36425 [==============================] - 100s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 9/100\n",
      "36425/36425 [==============================] - 98s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 10/100\n",
      "36425/36425 [==============================] - 106s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 11/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 12/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 13/100\n",
      "36425/36425 [==============================] - 85s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 14/100\n",
      "36425/36425 [==============================] - 85s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 15/100\n",
      "36425/36425 [==============================] - 78s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 16/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 17/100\n",
      "36425/36425 [==============================] - 85s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 18/100\n",
      "36425/36425 [==============================] - 84s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 19/100\n",
      "36425/36425 [==============================] - 84s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528s - loss: -8.3519 - binar\n",
      "Epoch 20/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 21/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 22/100\n",
      "36425/36425 [==============================] - 84s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 23/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 24/100\n",
      "36425/36425 [==============================] - 84s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 25/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 26/100\n",
      "36425/36425 [==============================] - 84s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 27/100\n",
      "36425/36425 [==============================] - 85s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 28/100\n",
      "36425/36425 [==============================] - 84s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 29/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 30/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 31/100\n",
      "36425/36425 [==============================] - 93s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 32/100\n",
      "36425/36425 [==============================] - 150s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 33/100\n",
      "36425/36425 [==============================] - 153s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 34/100\n",
      "36425/36425 [==============================] - 152s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 35/100\n",
      "36425/36425 [==============================] - 130s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 36/100\n",
      "36425/36425 [==============================] - 133s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 37/100\n",
      "36425/36425 [==============================] - 143s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 38/100\n",
      "36425/36425 [==============================] - 135s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 39/100\n",
      "36425/36425 [==============================] - 143s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 40/100\n",
      "36425/36425 [==============================] - 139s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 41/100\n",
      "36425/36425 [==============================] - 148s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 42/100\n",
      "36425/36425 [==============================] - 148s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 43/100\n",
      "36425/36425 [==============================] - 141s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 44/100\n",
      "36425/36425 [==============================] - 141s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 45/100\n",
      "36425/36425 [==============================] - 146s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 46/100\n",
      "36425/36425 [==============================] - 144s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 47/100\n",
      "36425/36425 [==============================] - 147s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 48/100\n",
      "36425/36425 [==============================] - 142s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 49/100\n",
      "36425/36425 [==============================] - 134s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 50/100\n",
      "36425/36425 [==============================] - 131s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 51/100\n",
      "36425/36425 [==============================] - 131s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 52/100\n",
      "36425/36425 [==============================] - 140s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 53/100\n",
      "36425/36425 [==============================] - 147s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 54/100\n",
      "36425/36425 [==============================] - 147s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 55/100\n",
      "36425/36425 [==============================] - 147s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 56/100\n",
      "36425/36425 [==============================] - 150s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 57/100\n",
      "36425/36425 [==============================] - 50276s 1s/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 58/100\n",
      "36425/36425 [==============================] - 35s 960us/sample - loss: -8.3441 - binary_accuracy: 0.4528- loss: -8.3501 - bin\n",
      "Epoch 59/100\n",
      "36425/36425 [==============================] - 52s 1ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 60/100\n",
      "36425/36425 [==============================] - 125s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 61/100\n",
      "36425/36425 [==============================] - 109s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 62/100\n",
      "36425/36425 [==============================] - 116s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 63/100\n",
      "36425/36425 [==============================] - 125s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 64/100\n",
      "36425/36425 [==============================] - 97s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 65/100\n",
      "36425/36425 [==============================] - 97s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 66/100\n",
      "36425/36425 [==============================] - 95s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 67/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 68/100\n",
      "36425/36425 [==============================] - 86s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 69/100\n",
      "36425/36425 [==============================] - 106s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36425/36425 [==============================] - 123s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 71/100\n",
      "36425/36425 [==============================] - 127s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 72/100\n",
      "36425/36425 [==============================] - 130s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 73/100\n",
      "36425/36425 [==============================] - 89s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 74/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 75/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 76/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 77/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 78/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 79/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 80/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 81/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 82/100\n",
      "36425/36425 [==============================] - 105s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 83/100\n",
      "36425/36425 [==============================] - 134s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 84/100\n",
      "36425/36425 [==============================] - 132s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 85/100\n",
      "36425/36425 [==============================] - 131s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 86/100\n",
      "36425/36425 [==============================] - 122s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 87/100\n",
      "36425/36425 [==============================] - 123s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 88/100\n",
      "36425/36425 [==============================] - 100s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 89/100\n",
      "36425/36425 [==============================] - 121s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 90/100\n",
      "36425/36425 [==============================] - 131s 4ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 91/100\n",
      "36425/36425 [==============================] - 103s 3ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 92/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 93/100\n",
      "36425/36425 [==============================] - 91s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 94/100\n",
      "36425/36425 [==============================] - 82s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 95/100\n",
      "36425/36425 [==============================] - 84s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 96/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 97/100\n",
      "36425/36425 [==============================] - 83s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 98/100\n",
      "36425/36425 [==============================] - 90s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 99/100\n",
      "36425/36425 [==============================] - 87s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n",
      "Epoch 100/100\n",
      "36425/36425 [==============================] - 84s 2ms/sample - loss: -8.3441 - binary_accuracy: 0.4528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a53b700c8>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(1, input_dim=260, activation='relu'))\n",
    "adagrad=optimizers.Adagrad(lr=0.01, epsilon=1e-6)\n",
    "model2.compile(optimizer=adagrad ,loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "\n",
    "model2.fit(trainX,trainY, batch_size=1, epochs=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45532 samples\n",
      "Epoch 1/100\n",
      "45532/45532 [==============================] - 49s 1ms/sample - loss: -146.7590 - binary_accuracy: 0.4531\n",
      "Epoch 2/100\n",
      "45532/45532 [==============================] - 44s 963us/sample - loss: -441.2621 - binary_accuracy: 0.4532\n",
      "Epoch 3/100\n",
      "45532/45532 [==============================] - 48s 1ms/sample - loss: -735.8174 - binary_accuracy: 0.4532\n",
      "Epoch 4/100\n",
      "45532/45532 [==============================] - 45s 984us/sample - loss: -1030.3730 - binary_accuracy: 0.4532\n",
      "Epoch 5/100\n",
      "45532/45532 [==============================] - 40s 880us/sample - loss: -1324.9287 - binary_accuracy: 0.4532\n",
      "Epoch 6/100\n",
      "45532/45532 [==============================] - 42s 914us/sample - loss: -1619.4847 - binary_accuracy: 0.4532\n",
      "Epoch 7/100\n",
      "45532/45532 [==============================] - 41s 899us/sample - loss: -1914.0405 - binary_accuracy: 0.4532\n",
      "Epoch 8/100\n",
      "45532/45532 [==============================] - 41s 909us/sample - loss: -2208.5960 - binary_accuracy: 0.4532\n",
      "Epoch 9/100\n",
      "45532/45532 [==============================] - 40s 873us/sample - loss: -2503.1515 - binary_accuracy: 0.4532\n",
      "Epoch 10/100\n",
      "45532/45532 [==============================] - 43s 946us/sample - loss: -2797.7070 - binary_accuracy: 0.4532\n",
      "Epoch 11/100\n",
      "45532/45532 [==============================] - 41s 893us/sample - loss: -3092.2626 - binary_accuracy: 0.4532\n",
      "Epoch 12/100\n",
      "45532/45532 [==============================] - 43s 935us/sample - loss: -3386.8186 - binary_accuracy: 0.4532\n",
      "Epoch 13/100\n",
      "45532/45532 [==============================] - 40s 875us/sample - loss: -3681.3745 - binary_accuracy: 0.4532\n",
      "Epoch 14/100\n",
      "45532/45532 [==============================] - 39s 863us/sample - loss: -3975.9301 - binary_accuracy: 0.4532\n",
      "Epoch 15/100\n",
      "45532/45532 [==============================] - 64s 1ms/sample - loss: -4270.4860 - binary_accuracy: 0.4532\n",
      "Epoch 16/100\n",
      "45532/45532 [==============================] - 66s 1ms/sample - loss: -4565.0417 - binary_accuracy: 0.4532\n",
      "Epoch 17/100\n",
      "45532/45532 [==============================] - 67s 1ms/sample - loss: -4859.5974 - binary_accuracy: 0.4532\n",
      "Epoch 18/100\n",
      "45532/45532 [==============================] - 65s 1ms/sample - loss: -5154.1528 - binary_accuracy: 0.4532\n",
      "Epoch 19/100\n",
      "45532/45532 [==============================] - 67s 1ms/sample - loss: -5448.7080 - binary_accuracy: 0.4532\n",
      "Epoch 20/100\n",
      "45532/45532 [==============================] - 65s 1ms/sample - loss: -5743.2635 - binary_accuracy: 0.4532\n",
      "Epoch 21/100\n",
      "45532/45532 [==============================] - 66s 1ms/sample - loss: -6037.8198 - binary_accuracy: 0.4532\n",
      "Epoch 22/100\n",
      "45532/45532 [==============================] - 66s 1ms/sample - loss: -6332.3759 - binary_accuracy: 0.4532\n",
      "Epoch 23/100\n",
      "45532/45532 [==============================] - 67s 1ms/sample - loss: -6626.9305 - binary_accuracy: 0.4532\n",
      "Epoch 24/100\n",
      "45532/45532 [==============================] - 66s 1ms/sample - loss: -6921.4854 - binary_accuracy: 0.4532\n",
      "Epoch 25/100\n",
      "45532/45532 [==============================] - 66s 1ms/sample - loss: -7216.0401 - binary_accuracy: 0.4532\n",
      "Epoch 26/100\n",
      "45532/45532 [==============================] - 67s 1ms/sample - loss: -7510.5951 - binary_accuracy: 0.4532\n",
      "Epoch 27/100\n",
      "45532/45532 [==============================] - 67s 1ms/sample - loss: -7805.1499 - binary_accuracy: 0.4532\n",
      "Epoch 28/100\n",
      "45532/45532 [==============================] - 67s 1ms/sample - loss: -8099.7047 - binary_accuracy: 0.4532\n",
      "Epoch 29/100\n",
      "45532/45532 [==============================] - 62s 1ms/sample - loss: -8394.2596 - binary_accuracy: 0.4532\n",
      "Epoch 30/100\n",
      "45532/45532 [==============================] - 39s 849us/sample - loss: -8688.8149 - binary_accuracy: 0.4532\n",
      "Epoch 31/100\n",
      "45532/45532 [==============================] - 39s 847us/sample - loss: -8983.3697 - binary_accuracy: 0.4532\n",
      "Epoch 32/100\n",
      "45532/45532 [==============================] - 38s 837us/sample - loss: -9277.9255 - binary_accuracy: 0.4532\n",
      "Epoch 33/100\n",
      "45532/45532 [==============================] - 38s 839us/sample - loss: -9572.4826 - binary_accuracy: 0.4532\n",
      "Epoch 34/100\n",
      "45532/45532 [==============================] - 38s 843us/sample - loss: -9867.0393 - binary_accuracy: 0.4532\n",
      "Epoch 35/100\n",
      "45532/45532 [==============================] - 38s 839us/sample - loss: -10161.5960 - binary_accuracy: 0.4532\n",
      "Epoch 36/100\n",
      "45532/45532 [==============================] - 39s 847us/sample - loss: -10456.1531 - binary_accuracy: 0.4532\n",
      "Epoch 37/100\n",
      "45532/45532 [==============================] - 38s 835us/sample - loss: -10750.7107 - binary_accuracy: 0.4532\n",
      "Epoch 38/100\n",
      "45532/45532 [==============================] - 39s 860us/sample - loss: -11045.2682 - binary_accuracy: 0.4532\n",
      "Epoch 39/100\n",
      "45532/45532 [==============================] - 42s 918us/sample - loss: -11339.8258 - binary_accuracy: 0.4532\n",
      "Epoch 40/100\n",
      "45532/45532 [==============================] - 40s 885us/sample - loss: -11634.3806 - binary_accuracy: 0.4532\n",
      "Epoch 41/100\n",
      "45532/45532 [==============================] - 40s 885us/sample - loss: -11928.9334 - binary_accuracy: 0.4532\n",
      "Epoch 42/100\n",
      "45532/45532 [==============================] - 38s 837us/sample - loss: -12223.4863 - binary_accuracy: 0.4532\n",
      "Epoch 43/100\n",
      "45532/45532 [==============================] - 38s 840us/sample - loss: -12518.0391 - binary_accuracy: 0.4532\n",
      "Epoch 44/100\n",
      "45532/45532 [==============================] - 38s 836us/sample - loss: -12812.5926 - binary_accuracy: 0.4532\n",
      "Epoch 45/100\n",
      "45532/45532 [==============================] - 38s 836us/sample - loss: -13107.1478 - binary_accuracy: 0.4532\n",
      "Epoch 46/100\n",
      "45532/45532 [==============================] - 37s 821us/sample - loss: -13401.7030 - binary_accuracy: 0.4532\n",
      "Epoch 47/100\n",
      "45532/45532 [==============================] - 38s 831us/sample - loss: -13696.2581 - binary_accuracy: 0.4532\n",
      "Epoch 48/100\n",
      "45532/45532 [==============================] - 38s 841us/sample - loss: -13990.8133 - binary_accuracy: 0.4532\n",
      "Epoch 49/100\n",
      "45532/45532 [==============================] - 38s 838us/sample - loss: -14285.3683 - binary_accuracy: 0.4532\n",
      "Epoch 50/100\n",
      "45532/45532 [==============================] - 38s 837us/sample - loss: -14579.9241 - binary_accuracy: 0.4532\n",
      "Epoch 51/100\n",
      "45532/45532 [==============================] - 38s 836us/sample - loss: -14874.4809 - binary_accuracy: 0.4532\n",
      "Epoch 52/100\n",
      "45532/45532 [==============================] - 38s 834us/sample - loss: -15169.0383 - binary_accuracy: 0.4532\n",
      "Epoch 53/100\n",
      "45532/45532 [==============================] - 38s 837us/sample - loss: -15463.5959 - binary_accuracy: 0.4532\n",
      "Epoch 54/100\n",
      "45532/45532 [==============================] - 38s 833us/sample - loss: -15758.1528 - binary_accuracy: 0.4532\n",
      "Epoch 55/100\n",
      "45532/45532 [==============================] - 38s 842us/sample - loss: -16052.7095 - binary_accuracy: 0.4532\n",
      "Epoch 56/100\n",
      "45532/45532 [==============================] - 38s 836us/sample - loss: -16347.2671 - binary_accuracy: 0.4532\n",
      "Epoch 57/100\n",
      "45532/45532 [==============================] - 38s 831us/sample - loss: -16641.8250 - binary_accuracy: 0.4532\n",
      "Epoch 58/100\n",
      "45532/45532 [==============================] - 38s 840us/sample - loss: -16936.3822 - binary_accuracy: 0.4532\n",
      "Epoch 59/100\n",
      "45532/45532 [==============================] - 38s 833us/sample - loss: -17230.9401 - binary_accuracy: 0.4532\n",
      "Epoch 60/100\n",
      "45532/45532 [==============================] - 38s 838us/sample - loss: -17525.4978 - binary_accuracy: 0.4532\n",
      "Epoch 61/100\n",
      "45532/45532 [==============================] - 38s 829us/sample - loss: -17820.0552 - binary_accuracy: 0.4532\n",
      "Epoch 62/100\n",
      "45532/45532 [==============================] - 38s 831us/sample - loss: -18114.6123 - binary_accuracy: 0.4532\n",
      "Epoch 63/100\n",
      "45532/45532 [==============================] - 38s 836us/sample - loss: -18409.1685 - binary_accuracy: 0.4532\n",
      "Epoch 64/100\n",
      "45532/45532 [==============================] - 38s 838us/sample - loss: -18703.7232 - binary_accuracy: 0.4532\n",
      "Epoch 65/100\n",
      "45532/45532 [==============================] - 38s 837us/sample - loss: -18998.2775 - binary_accuracy: 0.4532\n",
      "Epoch 66/100\n",
      "45532/45532 [==============================] - 38s 832us/sample - loss: -19292.8314 - binary_accuracy: 0.4532\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45532/45532 [==============================] - 38s 841us/sample - loss: -19587.3856 - binary_accuracy: 0.4532- loss: -19579.7519 - binary_accu\n",
      "Epoch 68/100\n",
      "45532/45532 [==============================] - 38s 828us/sample - loss: -19881.9404 - binary_accuracy: 0.4532\n",
      "Epoch 69/100\n",
      "45532/45532 [==============================] - 38s 832us/sample - loss: -20176.4947 - binary_accuracy: 0.4532\n",
      "Epoch 70/100\n",
      "45532/45532 [==============================] - 38s 825us/sample - loss: -20471.0486 - binary_accuracy: 0.4532\n",
      "Epoch 71/100\n",
      "45532/45532 [==============================] - 38s 833us/sample - loss: -20765.6027 - binary_accuracy: 0.4532\n",
      "Epoch 72/100\n",
      "45532/45532 [==============================] - 38s 832us/sample - loss: -21060.1571 - binary_accuracy: 0.4532\n",
      "Epoch 73/100\n",
      "45532/45532 [==============================] - 38s 826us/sample - loss: -21354.7116 - binary_accuracy: 0.4532\n",
      "Epoch 74/100\n",
      "45532/45532 [==============================] - 38s 832us/sample - loss: -21649.2661 - binary_accuracy: 0.4532\n",
      "Epoch 75/100\n",
      "45532/45532 [==============================] - 38s 833us/sample - loss: -21943.8203 - binary_accuracy: 0.4532\n",
      "Epoch 76/100\n",
      "45532/45532 [==============================] - 38s 834us/sample - loss: -22238.3746 - binary_accuracy: 0.4532\n",
      "Epoch 77/100\n",
      "45532/45532 [==============================] - 38s 828us/sample - loss: -22532.9304 - binary_accuracy: 0.4532\n",
      "Epoch 78/100\n",
      "45532/45532 [==============================] - 38s 831us/sample - loss: -22827.4886 - binary_accuracy: 0.4532\n",
      "Epoch 79/100\n",
      "45532/45532 [==============================] - 38s 834us/sample - loss: -23122.0508 - binary_accuracy: 0.4532\n",
      "Epoch 80/100\n",
      "45532/45532 [==============================] - 38s 835us/sample - loss: -23416.6115 - binary_accuracy: 0.4532\n",
      "Epoch 81/100\n",
      "45532/45532 [==============================] - 38s 831us/sample - loss: -23711.1743 - binary_accuracy: 0.4532\n",
      "Epoch 82/100\n",
      "45532/45532 [==============================] - 38s 833us/sample - loss: -24005.7378 - binary_accuracy: 0.4532\n",
      "Epoch 83/100\n",
      "45532/45532 [==============================] - 38s 839us/sample - loss: -24300.3020 - binary_accuracy: 0.4532\n",
      "Epoch 84/100\n",
      "45532/45532 [==============================] - 38s 833us/sample - loss: -24594.8640 - binary_accuracy: 0.4532\n",
      "Epoch 85/100\n",
      "45532/45532 [==============================] - 38s 833us/sample - loss: -24889.4223 - binary_accuracy: 0.4532\n",
      "Epoch 86/100\n",
      "45532/45532 [==============================] - 38s 841us/sample - loss: -25183.9799 - binary_accuracy: 0.4532\n",
      "Epoch 87/100\n",
      "45532/45532 [==============================] - 38s 830us/sample - loss: -25478.5402 - binary_accuracy: 0.4532\n",
      "Epoch 88/100\n",
      "45532/45532 [==============================] - 38s 831us/sample - loss: -25773.1011 - binary_accuracy: 0.4532\n",
      "Epoch 89/100\n",
      "45532/45532 [==============================] - 38s 836us/sample - loss: -26067.6621 - binary_accuracy: 0.4532\n",
      "Epoch 90/100\n",
      "45532/45532 [==============================] - 38s 835us/sample - loss: -26362.2239 - binary_accuracy: 0.4532\n",
      "Epoch 91/100\n",
      "45532/45532 [==============================] - 38s 837us/sample - loss: -26656.7861 - binary_accuracy: 0.4532\n",
      "Epoch 92/100\n",
      "45532/45532 [==============================] - ETA: 0s - loss: -26953.4018 - binary_accuracy: 0.45 - 38s 836us/sample - loss: -26951.3492 - binary_accuracy: 0.4532\n",
      "Epoch 93/100\n",
      "45532/45532 [==============================] - 38s 828us/sample - loss: -27245.9124 - binary_accuracy: 0.4532\n",
      "Epoch 94/100\n",
      "45532/45532 [==============================] - 39s 846us/sample - loss: -27540.4756 - binary_accuracy: 0.4532\n",
      "Epoch 95/100\n",
      "45532/45532 [==============================] - 38s 832us/sample - loss: -27835.0389 - binary_accuracy: 0.4532\n",
      "Epoch 96/100\n",
      "45532/45532 [==============================] - 39s 851us/sample - loss: -28129.6029 - binary_accuracy: 0.4532\n",
      "Epoch 97/100\n",
      "45532/45532 [==============================] - 39s 852us/sample - loss: -28424.1666 - binary_accuracy: 0.4532\n",
      "Epoch 98/100\n",
      "45532/45532 [==============================] - 39s 857us/sample - loss: -28718.7311 - binary_accuracy: 0.4532\n",
      "Epoch 99/100\n",
      "45532/45532 [==============================] - 39s 855us/sample - loss: -29013.2964 - binary_accuracy: 0.4532\n",
      "Epoch 100/100\n",
      "45532/45532 [==============================] - 39s 859us/sample - loss: -29307.8603 - binary_accuracy: 0.4532\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lr_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-c03b4704d298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlr_ped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_real\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test_ohe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mlr_pred_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mlr_pred_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'voted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mlr_pred_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_pred_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_pred' is not defined"
     ]
    }
   ],
   "source": [
    "lr_real=Sequential()\n",
    "lr_real.add(Dense(1, input_dim=260, activation='sigmoid'))\n",
    "lr_real.compile(optimizer='adam' ,loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "\n",
    "lr_real.fit(data_train_ohe,target_num, batch_size=3, epochs=100, shuffle=False)\n",
    "\n",
    "lr_pred=lr_real.predict(data_test_ohe)\n",
    "\n",
    "lr_pred_df=pd.DataFrame(lr_pred)\n",
    "lr_pred_df.columns=['voted']\n",
    "lr_pred_df['index']=lr_pred_df.index\n",
    "lr_pred_df=lr_pred_df.set_index('index')\n",
    "\n",
    "lr_pred_df.to_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/test_prediction_LogisiticRegression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred=lr_real.predict(data_test_ohe)\n",
    "\n",
    "lr_pred_df=pd.DataFrame(lr_pred)\n",
    "lr_pred_df.columns=['voted']\n",
    "lr_pred_df['index']=lr_pred_df.index\n",
    "lr_pred_df=lr_pred_df.set_index('index')\n",
    "\n",
    "lr_pred_df.to_csv('C:/Users/castl/Desktop/2020_job_academy/project/voting_psychology/test_prediction_LogisiticRegression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
